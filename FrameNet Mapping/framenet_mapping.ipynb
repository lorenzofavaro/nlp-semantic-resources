{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import framenet, wordnet\n",
    "from nltk.corpus.reader.framenet import AttrDict\n",
    "from nltk.corpus.reader.wordnet import Synset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "from random import seed, randint\n",
    "import hashlib\n",
    "import re\n",
    "import json\n",
    "from typing import AnyStr, List, Set, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stop_words_FULL.txt') as f:\n",
    "    stop_words = {line for line in f.read().splitlines()}\n",
    "\n",
    "with open('data/frame_annotations.json') as f:\n",
    "    frame_annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentence: AnyStr) -> Set[AnyStr]:\n",
    "    return set(remove_stopwords(tokenize_sentence(remove_punctuation(sentence))))\n",
    "\n",
    "\n",
    "def remove_stopwords(words: List[AnyStr]) -> List[AnyStr]:\n",
    "    return [value for value in words if value not in stop_words]\n",
    "\n",
    "\n",
    "# Get tokens from sentence\n",
    "def tokenize_sentence(sentence: AnyStr) -> List[AnyStr]:\n",
    "    words = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        words.append(lmtzr.lemmatize(tag[0]).lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "# Remove punctuation and multiple spaces\n",
    "def remove_punctuation(sentence: AnyStr) -> AnyStr:\n",
    "    return re.sub('\\s\\s+', ' ', re.sub(r'[^\\w\\s]', '', sentence))\n",
    "\n",
    "\n",
    "# Lexical unit names are in the form <lu>.PoS, so we get rid of the last part\n",
    "def clean_lu_name(lu_name: AnyStr) -> AnyStr:\n",
    "    return lu_name.split('.')[0]\n",
    "\n",
    "\n",
    "# Lexical unit definitions are in the form <type>: def, so we get rid of the first part\n",
    "def clean_lu_definition(lu_definition: AnyStr) -> AnyStr:\n",
    "    return lu_definition.split(':')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that contains the CONTEXTS associated with the frame, its frame elements and its lexical units\n",
    "class ContextsFrame:\n",
    "    def __init__(self, frame_id: int, frame_name: AnyStr, frame_context: Set[AnyStr], frame_elements_contexts: Dict[AnyStr, Set[AnyStr]], lexical_units_contexts: Dict[AnyStr, Set[AnyStr]]):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_context = frame_context\n",
    "        self.frame_elements_contexts = frame_elements_contexts\n",
    "        self.lexical_units_contexts = lexical_units_contexts\n",
    "    \n",
    "    def get_frame_id(self) -> int:\n",
    "        return self.frame_id\n",
    "\n",
    "    def get_frame_name(self) -> AnyStr:\n",
    "        return self.frame_name\n",
    "    \n",
    "    def get_frame_context(self) -> Set[AnyStr]:\n",
    "        return self.frame_context\n",
    "    \n",
    "    def get_frame_elements_contexts(self) -> Dict[AnyStr, Set[AnyStr]]:\n",
    "        return self.frame_elements_contexts\n",
    "\n",
    "    def get_lexical_units_contexts(self) -> Dict[AnyStr, Set[AnyStr]]:\n",
    "        return self.lexical_units_contexts\n",
    "    \n",
    "    def __str__(self) -> AnyStr:\n",
    "        header = f'[{self.frame_id}] {self.frame_name}'\n",
    "        context = f'FRAME CONTEXT:\\n{self.frame_context}'\n",
    "        fe_contexts = f'ELEMENTS CONTEXTS:\\n{self.frame_elements_contexts}'\n",
    "        lu_contexts = f'LEXICAL UNITS CONTEXTS:\\n{self.lexical_units_contexts}'\n",
    "        return '\\n'.join([header, context, fe_contexts, lu_contexts])\n",
    "    \n",
    "\n",
    "# Class that contains the SYNSETS associated with the frame, its frame elements and its lexical units\n",
    "class SynsetsFrame:\n",
    "    def __init__(self, frame_id: int, frame_name: AnyStr, frame_synset: Synset, frame_elements_synsets: Dict[AnyStr, Synset], lexical_units_synsets: Dict[AnyStr, Synset]):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_synset = frame_synset\n",
    "        self.frame_elements_synsets = frame_elements_synsets\n",
    "        self.lexical_units_synsets = lexical_units_synsets\n",
    "\n",
    "    def get_frame_id(self) -> int:\n",
    "        return self.frame_id\n",
    "    \n",
    "    def get_frame_name(self) -> AnyStr:\n",
    "        return self.frame_name\n",
    "\n",
    "    def get_frame_synset(self) -> Synset:\n",
    "        return self.frame_synset\n",
    "\n",
    "    def get_frame_elements_synsets(self) -> Dict[AnyStr, Synset]:\n",
    "        return self.frame_elements_synsets\n",
    "\n",
    "    def get_lexical_units_synsets(self) -> Dict[AnyStr, Synset]:\n",
    "        return self.lexical_units_synsets\n",
    "\n",
    "    def __str__(self) -> AnyStr:\n",
    "        header = f'[{self.frame_id}] {self.frame_name}'\n",
    "        context = f'FRAME SYNSET: {self.frame_synset} ({self.frame_synset.definition()})'\n",
    "        fe_synsets = f'ELEMENTS SYNSETS:\\n{self.frame_elements_synsets}'\n",
    "        lu_synsets = f'LEXICAL UNITS SYNSETS: {self.lexical_units_synsets}'\n",
    "        return '\\n'.join([header, context, fe_synsets, lu_synsets])\n",
    "    \n",
    "    def compare(self, other) -> float:\n",
    "        total = 0\n",
    "        equal = 0\n",
    "\n",
    "        if not (self.frame_id == other.get_frame_id() and self.frame_name == other.get_frame_name()):\n",
    "            return 0\n",
    "        \n",
    "        total += 1\n",
    "        if self.frame_synset == other.get_frame_synset():\n",
    "            equal += 1\n",
    "        \n",
    "        other_fes = other.get_frame_elements_synsets()\n",
    "        common_fe_keys = self.frame_elements_synsets.keys() & other_fes.keys()\n",
    "        for fe_key in common_fe_keys:\n",
    "            total += 1\n",
    "            equal += 1 if self.frame_elements_synsets[fe_key] == other_fes[fe_key] else 0\n",
    "        \n",
    "        other_lus = other.get_lexical_units_synsets()\n",
    "        common_lu_keys = self.lexical_units_synsets.keys() & other_lus.keys()\n",
    "        for lu_key in common_lu_keys:\n",
    "            total += 1\n",
    "            equal += 1 if self.lexical_units_synsets[lu_key] == other_lus[lu_key] else 0\n",
    "        \n",
    "        return equal / total\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash the surname and use it as base index, then get 5 frames of framenet through (frames[base_idx + random_offset_i])\n",
    "def get_frameset_for_student(surname: AnyStr, frame_num: int=5) -> List[AttrDict]:\n",
    "    frames = list()\n",
    "    frames_count = len(framenet.frames())\n",
    "    framenet_IDs = [f.ID for f in framenet.frames()]\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % frames_count)\n",
    "    i = 0\n",
    "    seed(0)\n",
    "    \n",
    "    while i < frame_num:\n",
    "        offset = randint(0, frames_count)\n",
    "        frame_id = framenet_IDs[(base_idx + offset) % frames_count]\n",
    "        f = framenet.frame(frame_id)\n",
    "\n",
    "        if frame_id not in frames:\n",
    "            frames.append(f)\n",
    "            i += 1\n",
    "        \n",
    "    return frames\n",
    "\n",
    "\n",
    "# Return the context of a WordNet Synset using definition, examples, hypernyms and hyponyms\n",
    "def context_for_synset(synset: Synset) -> Set[AnyStr]:\n",
    "    context = set()\n",
    "\n",
    "    context.update(bag_of_words(synset.definition()))\n",
    "    for example in synset.examples():\n",
    "        context.update(bag_of_words(example))\n",
    "    \n",
    "    for hypernym in synset.hypernyms(): # differently from before, we also add hypernyms to the context\n",
    "        context.update(bag_of_words(hypernym.definition()))\n",
    "        for example in hypernym.examples():\n",
    "            context.update(bag_of_words(example))\n",
    "            \n",
    "    for hyponym in synset.hyponyms(): # differently from before, we also add hyponyms to the context\n",
    "        context.update(bag_of_words(hyponym.definition()))\n",
    "        for example in hyponym.examples():\n",
    "            context.update(bag_of_words(example))\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# Select regent from frame's name\n",
    "def select_regent(words: List[AnyStr]) -> AnyStr:\n",
    "    best = 0\n",
    "    tag = nltk.tag.pos_tag(words)\n",
    "    for i in range(0, len(words)):\n",
    "        if tag[i][1] == 'VB':\n",
    "            return words[i]\n",
    "        elif tag[i][1] == 'NN' and tag[best][1] != 'NN':\n",
    "           best = i\n",
    "    return words[best]\n",
    "\n",
    "\n",
    "# Compute best synset intersecting FrameNet context and WordNet context (FrameNet mapped version of Lesk Algorithm)\n",
    "def compute_score(wn_word: AnyStr, fn_context: Set[AnyStr]) -> Synset:\n",
    "    synsets = wordnet.synsets(wn_word)\n",
    "    if not synsets:\n",
    "        return None\n",
    "\n",
    "    best_synset = synsets[0]\n",
    "    max_score = 0\n",
    "\n",
    "    for synset in synsets:\n",
    "        synset_context = context_for_synset(synset)\n",
    "        score = len(fn_context & synset_context) + 1 # score is computed using bag of words's approach\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_synset = synset\n",
    "    return best_synset\n",
    "\n",
    "\n",
    "# Get a ContextsFrame for each of the input frames\n",
    "def get_contexts_frames(frames: List[AttrDict]) -> List[ContextsFrame]:\n",
    "    context_frames = list()\n",
    "    for frame in frames:\n",
    "        frame_elements_contexts = dict()\n",
    "        lexical_units_contexts = dict()\n",
    "        frame_context = bag_of_words(frame.definition) # get context for the frame itself\n",
    "\n",
    "        for fev in frame.FE.values():\n",
    "            fe_context = bag_of_words(fev.definition) # get context for frame element\n",
    "            frame_elements_contexts[fev.name] = fe_context\n",
    "            frame_context.update(fe_context) # update frame_context\n",
    "        \n",
    "        for luv in frame.lexUnit.values():\n",
    "            lu_context = bag_of_words(clean_lu_definition(luv.definition)) # get context for lexical units\n",
    "            lexical_units_contexts[luv.name] = lu_context\n",
    "            frame_context.update(lu_context) # update frame_context\n",
    "        \n",
    "        contextsFrame = ContextsFrame(frame.ID, frame.name, frame_context, frame_elements_contexts, lexical_units_contexts)\n",
    "        context_frames.append(contextsFrame)\n",
    "    return context_frames\n",
    "\n",
    "\n",
    "# Get a SynsetsFrame for each of the input contextsFrame\n",
    "def get_synsets_frames(contexts_frames: List[ContextsFrame]) -> List[SynsetsFrame]:\n",
    "    synsets_frames = list()\n",
    "    for contexts_frame in contexts_frames:\n",
    "        frame_elements_synsets = dict()\n",
    "        lexical_units_synsets = dict()\n",
    "\n",
    "        for fe_name, fe_context in contexts_frame.get_frame_elements_contexts().items():\n",
    "            score = compute_score(fe_name, fe_context) # compute the best sense (score) for each frame element\n",
    "            if score:\n",
    "                frame_elements_synsets[fe_name] = score\n",
    "        \n",
    "        for lu_name, lu_context in contexts_frame.get_lexical_units_contexts().items():\n",
    "            score = compute_score(clean_lu_name(lu_name), lu_context) # compute the best sense (score) for each frame lexical unit\n",
    "            if score:\n",
    "                lexical_units_synsets[lu_name] = score\n",
    "        \n",
    "        frame_id = contexts_frame.get_frame_id()\n",
    "        frame_name = contexts_frame.get_frame_name()\n",
    "        frame_synset = compute_score(select_regent(frame_name.split('_')), contexts_frame.get_frame_context()) # compute the best sense (score) for the frame context\n",
    "\n",
    "        synsetsFrame = SynsetsFrame(frame_id, frame_name, frame_synset, frame_elements_synsets, lexical_units_synsets)\n",
    "        synsets_frames.append(synsetsFrame)\n",
    "    return synsets_frames\n",
    "\n",
    "\n",
    "def disambiguate_frames(frameset: List[AttrDict], verbose=True) -> List[SynsetsFrame]:\n",
    "    contexts_frames = get_contexts_frames(frameset)\n",
    "    synsets_frames = get_synsets_frames(contexts_frames)\n",
    "\n",
    "    if verbose:\n",
    "        separator = '-'*40\n",
    "        print(f'{separator} FRAMESET FOR STUDENT {surname} {separator}')\n",
    "        for frame in frameset:\n",
    "            print(f'{frame.name}\\n - Regent: {select_regent(frame.name.split(\"_\"))}\\n - Definition: {frame.definition}\\n')\n",
    "\n",
    "        print(f'\\n{separator} OBTAINED CONTEXTS FRAMES {separator}\\n')\n",
    "        for frame in contexts_frames:\n",
    "            print(f'{frame}\\n')\n",
    "\n",
    "        print(f'{separator} OBTAINED SYNSETS FRAMES {separator}\\n')\n",
    "        for frame in synsets_frames:\n",
    "            print(f'{frame}\\n')\n",
    "    \n",
    "    return synsets_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disambiguation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotated_synsets_frames(surname: AnyStr) -> List[SynsetsFrame]:\n",
    "    synsets_frames = list()\n",
    "    for f in frame_annotations[surname]:\n",
    "        frame_id = f['id']\n",
    "        frame_name = f['name']\n",
    "        frame_synset = wordnet.synset(f['synset'])\n",
    "        frame_elements_synsets = {fe_name: wordnet.synset(synset_id) for fe_name, synset_id in f['elements_synsets'].items()}\n",
    "        lexical_units_synsets = {lu_name: wordnet.synset(synset_id) for lu_name, synset_id in f['lexical_units_synsets'].items()}\n",
    "            \n",
    "        synsets_frames.append(SynsetsFrame(frame_id, frame_name, frame_synset, frame_elements_synsets, lexical_units_synsets))\n",
    "    \n",
    "    return synsets_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for Favaro frameset: 0.71\n"
     ]
    }
   ],
   "source": [
    "surname = 'Favaro'\n",
    "synsets_frames = disambiguate_frames(get_frameset_for_student(surname), verbose=False)\n",
    "annotated_synsets_frames = load_annotated_synsets_frames(surname)\n",
    "\n",
    "accuracy_list = [synset_frame.compare(annotated_synset_frame) for synset_frame, annotated_synset_frame in zip(synsets_frames, annotated_synsets_frames)]\n",
    "avg_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "\n",
    "print(f'Average accuracy for {surname} frameset: {avg_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for Senese frameset: 0.12\n"
     ]
    }
   ],
   "source": [
    "surname = 'Senese'\n",
    "synsets_frames = disambiguate_frames(get_frameset_for_student(surname), verbose=False)\n",
    "print(get_frameset_for_student(surname))\n",
    "annotated_synsets_frames = load_annotated_synsets_frames(surname)\n",
    "\n",
    "accuracy_list = [synset_frame.compare(annotated_synset_frame) for synset_frame, annotated_synset_frame in zip(synsets_frames, annotated_synsets_frames)]\n",
    "avg_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "\n",
    "print(f'Average accuracy for {surname} frameset: {avg_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('part.n.01') something determined in relation to something that includes it\n",
      "Synset('part.n.02') something less than the whole of a human artifact\n",
      "Synset('part.n.03') a portion of a natural object\n",
      "Synset('part.n.04') that which concerns a person with regard to a particular role or situation\n",
      "Synset('region.n.01') the extended spatial location of something\n",
      "Synset('function.n.03') the actions and activities assigned to or required or expected of a person or group\n",
      "Synset('character.n.04') an actor's portrayal of someone in a play\n",
      "Synset('share.n.01') assets belonging to or due to or contributed by an individual person or group\n",
      "Synset('part.n.09') one of the portions into which something is regarded as divided and which together constitute a whole\n",
      "Synset('part.n.10') a line of scalp that can be seen when sections of hair are combed in opposite directions\n",
      "Synset('part.n.11') the melody carried by a particular voice or instrument in polyphonic music\n",
      "Synset('contribution.n.01') the part played by a person in bringing about a result\n",
      "Synset('separate.v.09') go one's own way; move apart\n",
      "Synset('separate.v.08') discontinue an association or relation; go different ways\n",
      "Synset('depart.v.03') leave\n",
      "Synset('separate.v.12') come apart\n",
      "Synset('separate.v.02') force, take, or pull apart\n",
      "Synset('partially.r.01') in part; in some degree; not wholly\n"
     ]
    }
   ],
   "source": [
    "for synset in wordnet.synsets('part'):\n",
    "    print(synset, synset.definition())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "404b64e01f57285674b9751162c2ed4527d694a9d1b08ef777de9504d46378cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
