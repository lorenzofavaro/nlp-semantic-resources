{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import framenet, wordnet\n",
    "from nltk.corpus.reader.framenet import AttrDict\n",
    "from nltk.corpus.reader.wordnet import Synset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "from random import seed, randint\n",
    "import hashlib\n",
    "import re\n",
    "from typing import AnyStr, List, Set, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stop_words_FULL.txt') as f:\n",
    "    stop_words = {line for line in f.read().splitlines()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(sentence: AnyStr) -> Set[AnyStr]:\n",
    "    return set(remove_stopwords(tokenize_sentence(remove_punctuation(sentence))))\n",
    "\n",
    "\n",
    "def remove_stopwords(words: List[AnyStr]) -> List[AnyStr]:\n",
    "    return [value for value in words if value not in stop_words]\n",
    "\n",
    "\n",
    "# Get tokens from sentence\n",
    "def tokenize_sentence(sentence: AnyStr) -> List[AnyStr]:\n",
    "    words = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        words.append(lmtzr.lemmatize(tag[0]).lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "# Remove punctuation and multiple spaces\n",
    "def remove_punctuation(sentence: AnyStr) -> AnyStr:\n",
    "    return re.sub('\\s\\s+', ' ', re.sub(r'[^\\w\\s]', '', sentence))\n",
    "\n",
    "\n",
    "# Lexical unit names are in the form <lu>.PoS, so we get rid of the last part\n",
    "def clean_lu_name(lu_name: AnyStr) -> AnyStr:\n",
    "    return lu_name.split('.')[0]\n",
    "\n",
    "\n",
    "# Lexical unit definitions are in the form <type>: def, so we get of the first part\n",
    "def clean_lu_definition(lu_definition: AnyStr) -> AnyStr:\n",
    "    return lu_definition.split(':')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that contains the CONTEXTS associated with the frame, its frame elements and its lexical units\n",
    "class ContextsFrame:\n",
    "    def __init__(self, frame_id: int, frame_name: AnyStr, frame_context: Set[AnyStr], frame_elements_contexts: Dict[AnyStr, Set[AnyStr]], lexical_units_contexts: Dict[AnyStr, Set[AnyStr]]):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_context = frame_context\n",
    "        self.frame_elements_contexts = frame_elements_contexts\n",
    "        self.lexical_units_contexts = lexical_units_contexts\n",
    "    \n",
    "    def get_frame_id(self) -> int:\n",
    "        return self.frame_id\n",
    "\n",
    "    def get_frame_name(self) -> AnyStr:\n",
    "        return self.frame_name\n",
    "    \n",
    "    def get_frame_context(self) -> Set[AnyStr]:\n",
    "        return self.frame_context\n",
    "    \n",
    "    def get_frame_elements_contexts(self) -> Dict[AnyStr, Set[AnyStr]]:\n",
    "        return self.frame_elements_contexts\n",
    "\n",
    "    def get_lexical_units_contexts(self) -> Dict[AnyStr, Set[AnyStr]]:\n",
    "        return self.lexical_units_contexts\n",
    "    \n",
    "    def __str__(self) -> AnyStr:\n",
    "        header = f'[{self.frame_id}] {self.frame_name}'\n",
    "        context = f'FRAME CONTEXT:\\n{self.frame_context}'\n",
    "        fe_contexts = f'ELEMENTS CONTEXTS:\\n{self.frame_elements_contexts}'\n",
    "        lu_contexts = f'LEXICAL UNITS CONTEXTS:\\n{self.lexical_units_contexts}'\n",
    "        return '\\n'.join([header, context, fe_contexts, lu_contexts])\n",
    "    \n",
    "\n",
    "# Class that contains the SYNSETS associated with the frame, its frame elements and its lexical units\n",
    "class SynsetsFrame:\n",
    "    def __init__(self, frame_id: int, frame_name: AnyStr, frame_synset: Synset, frame_elements_synsets: Dict[AnyStr, Synset], lexical_units_synsets: Dict[AnyStr, Synset]):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_synset = frame_synset\n",
    "        self.frame_elements_synsets = frame_elements_synsets\n",
    "        self.lexical_units_synsets = lexical_units_synsets\n",
    "\n",
    "    def get_frame_id(self) -> int:\n",
    "        return self.frame_id\n",
    "    \n",
    "    def get_frame_name(self) -> AnyStr:\n",
    "        return self.frame_name\n",
    "\n",
    "    def get_frame_synset(self) -> Synset:\n",
    "        return self.frame_synset\n",
    "\n",
    "    def get_frame_elements_synsets(self) -> Dict[AnyStr, Synset]:\n",
    "        return self.frame_elements_synsets\n",
    "\n",
    "    def get_lexical_units_synsets(self) -> Dict[AnyStr, Synset]:\n",
    "        return self.lexical_units_synsets\n",
    "\n",
    "    def __str__(self) -> AnyStr:\n",
    "        header = f'[{self.frame_id}] {self.frame_name}'\n",
    "        context = f'FRAME SYNSET: {self.frame_synset}'\n",
    "        fe_synsets = f'ELEMENTS SYNSETS:\\n{self.frame_elements_synsets}'\n",
    "        lu_synsets = f'LEXICAL UNITS SYNSETS: {self.lexical_units_synsets}'\n",
    "        return '\\n'.join([header, context, fe_synsets, lu_synsets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash the surname and use it as base index, then get 5 frames of framenet through (frames[base_idx + random_offset_i])\n",
    "def get_frameset_for_student(surname: AnyStr, frame_num: int=5) -> List[AttrDict]:\n",
    "    frames = list()\n",
    "    frames_count = len(framenet.frames())\n",
    "    framenet_IDs = [f.ID for f in framenet.frames()]\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % frames_count)\n",
    "    offset = 0\n",
    "    i = 0\n",
    "    seed(0)\n",
    "    \n",
    "    while i < frame_num:\n",
    "        frame_id = framenet_IDs[(base_idx + offset) % frames_count]\n",
    "        f = framenet.frame(frame_id)\n",
    "\n",
    "        if frame_id not in frames:\n",
    "            frames.append(f)\n",
    "            i += 1\n",
    "        \n",
    "        offset = randint(0, frames_count)\n",
    "    return frames\n",
    "\n",
    "\n",
    "# Return the context of a WordNet Synset using definition, examples, hypernyms and hyponyms\n",
    "def context_for_synset(synset: Synset) -> Set[AnyStr]:\n",
    "    context = set()\n",
    "\n",
    "    context.update(pre_processing(synset.definition()))\n",
    "    for example in synset.examples():\n",
    "        context.update(pre_processing(example))\n",
    "    \n",
    "    for hypernym in synset.hypernyms(): # differently from before, we also add hypernyms to the context\n",
    "        context.update(pre_processing(hypernym.definition()))\n",
    "        for example in hypernym.examples():\n",
    "            context.update(pre_processing(example))\n",
    "            \n",
    "    for hyponym in synset.hyponyms(): # differently from before, we also add hyponyms to the context\n",
    "        context.update(pre_processing(hyponym.definition()))\n",
    "        for example in hyponym.examples():\n",
    "            context.update(pre_processing(example))\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# Select regent from frame's name\n",
    "def select_regent(words: List[AnyStr]) -> AnyStr:\n",
    "    best = 0\n",
    "    tag = nltk.tag.pos_tag(words)\n",
    "    for i in range(0, len(words)):\n",
    "        if tag[i][1] == 'VB':\n",
    "            return words[i]\n",
    "        elif tag[i][1] == 'NN' and tag[best][1] != 'NN':\n",
    "           best = i\n",
    "    return words[best]\n",
    "\n",
    "\n",
    "# Compute best synset intersecting FrameNet context and WordNet context (FrameNet mapped version of Lesk Algorithm)\n",
    "def compute_score(wn_word: AnyStr, fn_context: Set[AnyStr]) -> Synset:\n",
    "    synsets = wordnet.synsets(wn_word)\n",
    "    if not synsets:\n",
    "        return None\n",
    "\n",
    "    best_synset = synsets[0]\n",
    "    max_score = 0\n",
    "\n",
    "    for synset in synsets:\n",
    "        synset_context = context_for_synset(synset)\n",
    "        score = len(fn_context & synset_context) + 1 # score is computed using bag of words's approach\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_synset = synset\n",
    "    return best_synset\n",
    "\n",
    "\n",
    "# Get a ContextsFrame for each of the input frames\n",
    "def get_contexts_frames(frames: List[AttrDict]) -> List[ContextsFrame]:\n",
    "    context_frames = list()\n",
    "    for frame in frames:\n",
    "        frame_elements_contexts = dict()\n",
    "        lexical_units_contexts = dict()\n",
    "        frame_context = pre_processing(frame.definition) # get context for the frame itself\n",
    "\n",
    "        for fev in frame.FE.values():\n",
    "            fe_context = pre_processing(fev.definition) # get context for frame element\n",
    "            frame_elements_contexts[fev.name] = fe_context\n",
    "            frame_context.update(fe_context) # update frame_context\n",
    "        \n",
    "        for luv in frame.lexUnit.values():\n",
    "            lu_context = pre_processing(clean_lu_definition(luv.definition)) # get context for lexical units\n",
    "            lexical_units_contexts[luv.name] = lu_context\n",
    "            frame_context.update(lu_context) # update frame_context\n",
    "        \n",
    "        contextsFrame = ContextsFrame(frame.ID, frame.name, frame_context, frame_elements_contexts, lexical_units_contexts)\n",
    "        context_frames.append(contextsFrame)\n",
    "    return context_frames\n",
    "\n",
    "\n",
    "# Get a SynsetsFrame for each of the input contextsFrame\n",
    "def get_synsets_frames(contexts_frames: List[ContextsFrame]) -> List[SynsetsFrame]:\n",
    "    synsets_frames = list()\n",
    "    for contexts_frame in contexts_frames:\n",
    "        frame_elements_synsets = dict()\n",
    "        lexical_units_synsets = dict()\n",
    "\n",
    "        for fe_name, fe_context in contexts_frame.get_frame_elements_contexts().items():\n",
    "            score = compute_score(fe_name, fe_context) # compute the best sense (score) for each frame element\n",
    "            if score:\n",
    "                frame_elements_synsets[fe_name] = score\n",
    "        \n",
    "        for lu_name, lu_context in contexts_frame.get_lexical_units_contexts().items():\n",
    "            score = compute_score(clean_lu_name(lu_name), lu_context) # compute the best sense (score) for each frame lexical unit\n",
    "            if score:\n",
    "                lexical_units_synsets[lu_name] = score\n",
    "        \n",
    "        frame_id = contexts_frame.get_frame_id()\n",
    "        frame_name = contexts_frame.get_frame_name()\n",
    "        frame_synset = compute_score(select_regent(frame_name.split('_')), contexts_frame.get_frame_context()) # compute the best sense (score) for the frame context\n",
    "\n",
    "        synsetsFrame = SynsetsFrame(frame_id, frame_name, frame_synset, frame_elements_synsets, lexical_units_synsets)\n",
    "        synsets_frames.append(synsetsFrame)\n",
    "    return synsets_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Frameset for student Favaro --\n",
      "Frame name: Notability - Regent: Notability\n",
      "Frame name: Court_examination - Regent: examination\n",
      "Frame name: Economy - Regent: Economy\n",
      "Frame name: Posture - Regent: Posture\n",
      "Frame name: Assemble - Regent: Assemble\n",
      "-- Obtained synsets frames --\n",
      "\n",
      "[2542] Notability\n",
      "FRAME SYNSET: Synset('luminary.n.01')\n",
      "ELEMENTS SYNSETS:\n",
      "{'Type': Synset('type.n.01'), 'Name': Synset('name.n.04'), 'Time': Synset('time.n.02'), 'Place': Synset('place.n.02'), 'Degree': Synset('degree.n.01')}\n",
      "LEXICAL UNITS SYNSETS: {'great.a': Synset('great.n.01'), 'notable.a': Synset('noteworthy.s.01')}\n",
      "\n",
      "[507] Court_examination\n",
      "FRAME SYNSET: Synset('interrogation.n.03')\n",
      "ELEMENTS SYNSETS:\n",
      "{'Questioner': Synset('inquirer.n.01'), 'Witness': Synset('witness.n.05'), 'Topic': Synset('subject.n.01'), 'Time': Synset('time.v.05'), 'Place': Synset('topographic_point.n.01'), 'Manner': Synset('manner.n.01'), 'Purpose': Synset('purpose.n.01'), 'Means': Synset('means.n.01'), 'Duration': Synset('duration.n.01')}\n",
      "LEXICAL UNITS SYNSETS: {'examine.v': Synset('probe.v.01'), 'cross.n': Synset('traverse.v.01'), 'cross-examination.n': Synset('cross-examination.n.01'), 'examination.n': Synset('interrogation.n.03')}\n",
      "\n",
      "[1572] Economy\n",
      "FRAME SYNSET: Synset('economy.n.01')\n",
      "ELEMENTS SYNSETS:\n",
      "{'Economy': Synset('economy.n.01'), 'Domain': Synset('sphere.n.01'), 'Descriptor': Synset('form.n.01')}\n",
      "LEXICAL UNITS SYNSETS: {'economy.n': Synset('economy.n.01'), 'economic.a': Synset('economic.a.01')}\n",
      "\n",
      "[18] Posture\n",
      "FRAME SYNSET: Synset('position.n.04')\n",
      "ELEMENTS SYNSETS:\n",
      "{'Agent': Synset('agent.n.01'), 'Location': Synset('location.n.01'), 'Degree': Synset('degree.n.01'), 'Depictive': Synset('delineative.s.01'), 'Manner': Synset('manner.n.01'), 'Time': Synset('time.n.01'), 'Purpose': Synset('purpose.n.01'), 'Duration': Synset('duration.n.03')}\n",
      "LEXICAL UNITS SYNSETS: {'bend.v': Synset('bend.v.01'), 'crouch.v': Synset('crouch.n.01'), 'hunch.v': Synset('hunch.v.01'), 'huddle.v': Synset('huddle.v.02'), 'kneel.v': Synset('kneel.v.01'), 'lean.v': Synset('lean.v.01'), 'lie.v': Synset('lie.v.02'), 'sit.v': Synset('sit.v.02'), 'slouch.v': Synset('slump.v.01'), 'sprawl.v': Synset('sprawl.v.01'), 'squat.v': Synset('squat.n.03'), 'stand.v': Synset('stand.v.01'), 'stoop.v': Synset('stoop.n.01'), 'bent.a': Synset('bend.v.01'), 'crouched.a': Synset('crouch.v.01'), 'huddled.a': Synset('huddle.v.01'), 'hunched.a': Synset('hunch.v.01'), 'sprawled.a': Synset('sprawl.v.01'), 'slouched.a': Synset('slump.v.01'), 'seated.a': Synset('seat.v.01'), 'posture.n': Synset('position.n.04'), 'stance.n': Synset('stance.n.01'), 'position.n': Synset('position.n.01'), 'cower.v': Synset('huddle.v.02'), 'shrink.v': Synset('shrivel.v.01')}\n",
      "\n",
      "[2237] Assemble\n",
      "FRAME SYNSET: Synset('meet.v.07')\n",
      "ELEMENTS SYNSETS:\n",
      "{'Individuals': Synset('person.n.01'), 'Group': Synset('group.n.01'), 'Manner': Synset('manner.n.01'), 'Place': Synset('topographic_point.n.01'), 'Means': Synset('means.n.01'), 'Time': Synset('time.v.05'), 'Purpose': Synset('purpose.n.01')}\n",
      "LEXICAL UNITS SYNSETS: {'meet.v': Synset('meet.v.02'), 'assemble.v': Synset('meet.v.07'), 'convene.v': Synset('convene.v.01')}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "surname = 'Favaro'\n",
    "frameset = get_frameset_for_student(surname)\n",
    "\n",
    "print(f'-- Frameset for student {surname} --')\n",
    "for frame in frameset:\n",
    "    print(f'Frame name: {frame.name} - Regent: {select_regent(frame.name.split(\"_\"))}')\n",
    "\n",
    "contexts_frames = get_contexts_frames(frameset)\n",
    "synsets_frames = get_synsets_frames(contexts_frames)\n",
    "\n",
    "print('-- Obtained synsets frames --\\n')\n",
    "for item in synsets_frames:\n",
    "    print(f'{item}\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "404b64e01f57285674b9751162c2ed4527d694a9d1b08ef777de9504d46378cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
